<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>C++并发 - rayrain's blog</title><meta name=keywords content="righteoux"><meta name=author content="rayrain"><meta property="og:title" content="C++并发"><meta property="og:site_name" content="rayrain's blog"><meta property="og:image" content="/img/author.jpg"><meta name=title content="C++并发 - rayrain's blog"><meta name=description content="C++"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i>
<a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span>
<span class=site-title>rayrain's blog</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle></p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span>
<span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=http://rayrain.xyz/post/cpp_concurrency/ itemprop=url>C++并发</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i>
<span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2022-05-15">2022-05-15</time></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i>
<span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>5013 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i>
<span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>11分钟</span></span>
<span id=/post/cpp_concurrency/ class=leancloud_visitors data-flag-title=C++并发>|
<i class="fa fa-binoculars fa-fw"></i>
<span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><h2 id=多线程编程>多线程编程</h2><p>并发:只存在一个处理器</p><p>并行:存在多个处理器</p><p>并行是并发的子集,统称为并发</p><p><strong>进程</strong>（英语：process），是指计算机中已运行的程序。进程为曾经是分时系统的基本运作单位。在面向进程设计的系统（如早期的UNIX，Linux 2.4及更早的版本）中，进程是程序的基本执行实体；</p><p><strong>线程</strong>（英语：thread）是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。</p><p>在默认的情况下，我们写的代码都是在进程的主线程中运行，除非开发者在程序中创建了新的线程。</p><p>当我们只有一个处理器时，所有的进程或线程会分时占用这个处理器。但如果系统中存在多个处理器时，则就可能有多个任务并行的运行在不同的处理器上。</p><p>任务会在何时占有处理器，通常是由操作系统的调度策略决定的</p><p>多线程API 由操作系统提供.</p><p>C++ 11 中,增加了多线程的支持</p><p><code>thread</code> 启动一个新线程</p><p>创建线程 <code>thread</code></p><p><code>join</code> :主线程等待这个线程结束</p><p><code>detach</code> 让线程独立运行 ,成为守护线程</p><p>访问共享数据的代码片段称之为<strong>临界区</strong>（critical section）</p><p><code>mutex</code>互斥加锁</p><p>条件量</p><p><code>wait</code></p><p><code>notify_all</code></p><p>本质上是线程间 共享的全局flag</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>#include &lt;iostream&gt;
</span></span><span style=display:flex><span>#include &lt;string&gt;
</span></span><span style=display:flex><span>#include &lt;thread&gt;
</span></span><span style=display:flex><span>#include &lt;mutex&gt;
</span></span><span style=display:flex><span>#include &lt;condition_variable&gt;
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>std::mutex m;
</span></span><span style=display:flex><span>std::condition_variable cv;
</span></span><span style=display:flex><span>std::string data;
</span></span><span style=display:flex><span>bool ready = false;
</span></span><span style=display:flex><span>bool processed = false;
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>void worker_thread()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    // Wait until main() sends data
</span></span><span style=display:flex><span>    std::unique_lock lk(m);
</span></span><span style=display:flex><span>    cv.wait(lk, []{return ready;});
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    // after the wait, we own the lock.
</span></span><span style=display:flex><span>    std::cout &lt;&lt; &#34;Worker thread is processing data\n&#34;;
</span></span><span style=display:flex><span>    data += &#34; after processing&#34;;
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    // Send data back to main()
</span></span><span style=display:flex><span>    processed = true;
</span></span><span style=display:flex><span>    std::cout &lt;&lt; &#34;Worker thread signals data processing completed\n&#34;;
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    // Manual unlocking is done before notifying, to avoid waking up
</span></span><span style=display:flex><span>    // the waiting thread only to block again (see notify_one for details)
</span></span><span style=display:flex><span>    lk.unlock();
</span></span><span style=display:flex><span>    cv.notify_one();
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>int main()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    std::thread worker(worker_thread);
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    data = &#34;Example data&#34;;
</span></span><span style=display:flex><span>    // send data to the worker thread
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        std::lock_guard lk(m);
</span></span><span style=display:flex><span>        ready = true;
</span></span><span style=display:flex><span>        std::cout &lt;&lt; &#34;main() signals data ready for processing\n&#34;;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    cv.notify_one();
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    // wait for the worker
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        std::unique_lock lk(m);
</span></span><span style=display:flex><span>        cv.wait(lk, []{return processed;});
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    std::cout &lt;&lt; &#34;Back in main(), data = &#34; &lt;&lt; data &lt;&lt; &#39;\n&#39;;
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    worker.join();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=future>future</h3><p><code>future</code>对象用来存储异步任务的执行结果,获取到这个对象的时候,可能异步任务还没执行.</p><p><code>wait()</code>来等待该异步任务结束</p><p><code>get()</code>获取该异步任务的结果</p><h3 id=async>async</h3><p>假设你需要一个长时间的运算,但并不迫切的需要这个值,可以启动一个新线程来执行这个计算,但是<code>thread</code> 并没有机制获得返回值.</p><p>可以使用<code>async</code>启动一个异步任务,而且会返回一个 <code>future</code>对象.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span><span style=color:#080>#include</span> <span style=color:#080>&lt;future&gt;</span><span style=color:#080>
</span></span></span><span style=display:flex><span><span style=color:#080>#include</span> <span style=color:#080>&lt;iostream&gt;</span><span style=color:#080>
</span></span></span><span style=display:flex><span><span style=color:#080></span><span style=color:#0b0;font-weight:700>int</span> <span style=color:#00a000>find_the_answer_to_ltuae</span>()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>return</span> <span style=color:#666>42</span>;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0b0;font-weight:700>void</span> <span style=color:#00a000>do_other_stuff</span>()
</span></span><span style=display:flex><span>{}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#0b0;font-weight:700>int</span> <span style=color:#00a000>main</span>()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    std<span style=color:#666>::</span>future<span style=color:#666>&lt;</span><span style=color:#0b0;font-weight:700>int</span><span style=color:#666>&gt;</span> the_answer<span style=color:#666>=</span>std<span style=color:#666>::</span>async(find_the_answer_to_ltuae);
</span></span><span style=display:flex><span>    do_other_stuff();
</span></span><span style=display:flex><span>    std<span style=color:#666>::</span>cout<span style=color:#666>&lt;&lt;</span><span style=color:#b44>&#34;The answer is &#34;</span><span style=color:#666>&lt;&lt;</span>the_answer.get()<span style=color:#666>&lt;&lt;</span>std<span style=color:#666>::</span>endl;
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><code>async</code>是否会启动一个新线程, 标准没有定义,由编译器决定,</p><p>如果一定要启动新线程,可以加入<code>launch::async</code>参数来说明.</p><p><code>std::launch::async</code> 在独立线程上执行</p><p><code>std::launch::deferred</code> 在<code>wait</code>或者<code>get</code>调用时执行 ,并不是独立线程</p><p><code>std::launch::async|std::launch::deferred</code> 在<code>wait</code>或者<code>get</code>调用时执行 ,并独立线程执行</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span><span style=color:#a2f;font-weight:700>auto</span> f6<span style=color:#666>=</span>std<span style=color:#666>::</span>async(std<span style=color:#666>::</span>launch<span style=color:#666>::</span>async,Y(),<span style=color:#666>1.2</span>); <span style=color:#080;font-style:italic>// 在新线程上执行
</span></span></span><span style=display:flex><span><span style=color:#080;font-style:italic></span><span style=color:#a2f;font-weight:700>auto</span> f7<span style=color:#666>=</span>std<span style=color:#666>::</span>async(std<span style=color:#666>::</span>launch<span style=color:#666>::</span>deferred,baz,std<span style=color:#666>::</span>ref(x)); <span style=color:#080;font-style:italic>// 在wait()或get()调用时执行 
</span></span></span><span style=display:flex><span><span style=color:#080;font-style:italic></span><span style=color:#a2f;font-weight:700>auto</span> f8<span style=color:#666>=</span>std<span style=color:#666>::</span>async( 
</span></span><span style=display:flex><span>	std<span style=color:#666>::</span>launch<span style=color:#666>::</span>deferred <span style=color:#666>|</span> std<span style=color:#666>::</span>launch<span style=color:#666>::</span>async, 
</span></span><span style=display:flex><span>	baz,std<span style=color:#666>::</span>ref(x)); <span style=color:#080;font-style:italic>// 实现选择执行方式
</span></span></span><span style=display:flex><span><span style=color:#080;font-style:italic></span><span style=color:#a2f;font-weight:700>auto</span> f9<span style=color:#666>=</span>std<span style=color:#666>::</span>async(baz,std<span style=color:#666>::</span>ref(x));
</span></span><span style=display:flex><span>f7.wait(); <span style=color:#080;font-style:italic>// 调用延迟函数
</span></span></span></code></pre></div><h3 id=promise>promise</h3><p>上面的例子,异步任务的结果是通过 return 返回的</p><p>但在一些时候，我们可能不能这么做：在得到任务结果之后，可能还有一些事情需要继续处理，例如清理工作。</p><p>异步任务不再直接返回计算结果，而是增加了一个<code>promise</code>对象来存放结果。</p><p>在任务计算完成之后，将总结过设置到<code>promise</code>对象上。一旦这里调用了<code>set_value</code>，其相关联的<code>future</code>对象就会就绪</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>#include &lt;vector&gt;
</span></span><span style=display:flex><span>#include &lt;thread&gt;
</span></span><span style=display:flex><span>#include &lt;future&gt;
</span></span><span style=display:flex><span>#include &lt;numeric&gt;
</span></span><span style=display:flex><span>#include &lt;iostream&gt;
</span></span><span style=display:flex><span>#include &lt;chrono&gt;
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>void accumulate(std::vector&lt;int&gt;::iterator first,
</span></span><span style=display:flex><span>                std::vector&lt;int&gt;::iterator last,
</span></span><span style=display:flex><span>                std::promise&lt;int&gt; accumulate_promise)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    int sum = std::accumulate(first, last, 0);
</span></span><span style=display:flex><span>    accumulate_promise.set_value(sum);  // Notify future
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>void do_work(std::promise&lt;void&gt; barrier)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    std::this_thread::sleep_for(std::chrono::seconds(1));
</span></span><span style=display:flex><span>    barrier.set_value();
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>int main()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    // Demonstrate using promise&lt;int&gt; to transmit a result between threads.
</span></span><span style=display:flex><span>    std::vector&lt;int&gt; numbers = { 1, 2, 3, 4, 5, 6 };
</span></span><span style=display:flex><span>    std::promise&lt;int&gt; accumulate_promise;
</span></span><span style=display:flex><span>    std::future&lt;int&gt; accumulate_future = accumulate_promise.get_future();
</span></span><span style=display:flex><span>    std::thread work_thread(accumulate, numbers.begin(), numbers.end(),
</span></span><span style=display:flex><span>                            std::move(accumulate_promise));
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    // future::get() will wait until the future has a valid result and retrieves it.
</span></span><span style=display:flex><span>    // Calling wait() before get() is not needed
</span></span><span style=display:flex><span>    //accumulate_future.wait();  // wait for result
</span></span><span style=display:flex><span>    std::cout &lt;&lt; &#34;result=&#34; &lt;&lt; accumulate_future.get() &lt;&lt; &#39;\n&#39;;
</span></span><span style=display:flex><span>    work_thread.join();  // wait for thread completion
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    // Demonstrate using promise&lt;void&gt; to signal state between threads.
</span></span><span style=display:flex><span>    std::promise&lt;void&gt; barrier;
</span></span><span style=display:flex><span>    std::future&lt;void&gt; barrier_future = barrier.get_future();
</span></span><span style=display:flex><span>    std::thread new_work_thread(do_work, std::move(barrier));
</span></span><span style=display:flex><span>    barrier_future.wait();
</span></span><span style=display:flex><span>    new_work_thread.join();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=packaged_task>packaged_task</h3><p><code>packaged_task</code>绑定到一个函数或者可调用对象上。当它被调用时，它就会调用其绑定的函数或者可调用对象。并且，可以通过与之相关联的<code>future</code>来获取任务的结果。调度程序只需要处理<code>packaged_task</code>，而非各个函数。</p><p>任务不会自己启动,你必须调用它.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>#include &lt;iostream&gt;
</span></span><span style=display:flex><span>#include &lt;cmath&gt;
</span></span><span style=display:flex><span>#include &lt;thread&gt;
</span></span><span style=display:flex><span>#include &lt;future&gt;
</span></span><span style=display:flex><span>#include &lt;functional&gt;
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>// unique function to avoid disambiguating the std::pow overload set
</span></span><span style=display:flex><span>int f(int x, int y) { return std::pow(x,y); }
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>void task_lambda()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    std::packaged_task&lt;int(int,int)&gt; task([](int a, int b) {
</span></span><span style=display:flex><span>        return std::pow(a, b); 
</span></span><span style=display:flex><span>    });
</span></span><span style=display:flex><span>    std::future&lt;int&gt; result = task.get_future();
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    task(2, 9);
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    std::cout &lt;&lt; &#34;task_lambda:\t&#34; &lt;&lt; result.get() &lt;&lt; &#39;\n&#39;;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>void task_bind()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    std::packaged_task&lt;int()&gt; task(std::bind(f, 2, 11));
</span></span><span style=display:flex><span>    std::future&lt;int&gt; result = task.get_future();
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    task();
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    std::cout &lt;&lt; &#34;task_bind:\t&#34; &lt;&lt; result.get() &lt;&lt; &#39;\n&#39;;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>void task_thread()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    std::packaged_task&lt;int(int,int)&gt; task(f);
</span></span><span style=display:flex><span>    std::future&lt;int&gt; result = task.get_future();
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    std::thread task_td(std::move(task), 2, 10);
</span></span><span style=display:flex><span>    task_td.join();
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    std::cout &lt;&lt; &#34;task_thread:\t&#34; &lt;&lt; result.get() &lt;&lt; &#39;\n&#39;;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>int main()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    task_lambda();
</span></span><span style=display:flex><span>    task_bind();
</span></span><span style=display:flex><span>    task_thread();
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=c内存模型>C++内存模型</h2><p>上文中提到的知识是以互斥体为中心的。为了避免竞争条件，是保证任何时候只有一个线程可以进入临界区</p><p>那些策略都是基于锁（lock-based）的：一旦有一个线程进入临界区，其他线程只能等待。</p><p>那有没有一种策略可以让其他线程不用等待，实现更好的并发呢？</p><p>答案是肯定的，这称之为免锁（lock-free）策略。不过实现这种策略要更麻烦一些，要对C++内存模型有更深入的理解，而这也是下面所要讲解的内容。</p><p>内存模型主要包含了下面三个部分：</p><ul><li><strong>原子操作</strong>：顾名思义，这类操作一旦执行就不会被打断，你无法看到它的中间状态，它要么是执行完成，要么没有执行。</li><li><strong>操作的局部顺序</strong>：一系列的操作不能被乱序。</li><li><strong>操作的可见性</strong>：定义了对于共享变量的操作如何对其他线程可见。</li></ul><p>事实上，开发者编写的代码和最终运行的程序往往会存在较大的差异，而运行结果与开发者预想一致，只是一种“假象”罢了。</p><p>之所以会产生差异，原因主要来自下面三个方面：</p><ul><li><strong>编译器优化</strong></li><li><strong>CPU out-of-order执行</strong></li><li><strong>CPU Cache不一致性</strong></li></ul><h3 id=memory-reorder>Memory Reorder</h3><p>“Memory Reorder”包含了编译器和处理器两种类型的乱序。</p><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/memory-reorder.png alt=img></p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>X = 0, Y = 0;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Thread 1: 
</span></span><span style=display:flex><span>X = 1; // ①
</span></span><span style=display:flex><span>r1 = Y; // ②
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Thread 2: 
</span></span><span style=display:flex><span>Y = 1;
</span></span><span style=display:flex><span>r2 = X;
</span></span></code></pre></div><p>线程1中事件发生的顺序虽然是先①后②，但是对于线程2来说，它看到结果可能却是先②后①。当然，线程1看线程2也是一样的。</p><p>甚至，<strong>当今的所有硬件平台，没有任何一个会提供完全的顺序一致（sequentially consistent）内存模型</strong>，因为这样做效率太低了。</p><p>不同的编译器和处理器对于Memory Reorder有不同的偏好，但它们都遵循一定的原则，那就是：<strong>不能修改单线程的行为</strong>（<a href=https://preshing.com/20120625/memory-ordering-at-compile-time/>Thou shalt not modify the behavior of a single-threaded program.</a>）。在这个基础上，它们可以做各种类型的优化。</p><h3 id=sequenced-before>sequenced-before</h3><p><code>sequenced-before</code> 单线程上的关系，这是一个非对称，可传递的成对关系</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>int i = 7; // ①
</span></span><span style=display:flex><span>i++;       // ②
</span></span></code></pre></div><p>这里的 ① sequenced-before ② 。</p><h3 id=happens-before>happens-before</h3><p>happens-before关系是sequenced-before关系的扩展，因为它还包含了不同线程之间的关系。</p><p>如果A happens-before B，则A的内存状态将在B操作执行之前就可见，这就为线程间的数据访问提供了保证。</p><p>同样的，这是一个非对称，可传递的关系。</p><p>如果A happens-before B，B happens-before C。则可推导出A happens-before C。</p><h3 id=synchronizes-with>synchronizes-with</h3><p>synchronizes-with描述的是一种状态传播（propagate）关系。如果A synchronizes-with B，则就是保证操作A的状态在操作B执行之前是可见的。</p><p>下文中我们将看到，原子操作的acquire-release具有synchronized-with关系。</p><p>除此之外，对于锁和互斥体的释放和获取可以达成synchronized-with关系，还有线程执行完成和join操作也能达成synchronized-with关系。</p><p>最后，借助 synchronizes-with 可以达成 happens-before 关系。</p><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/memory_model_relation.png alt=img></p><h2 id=原子>原子</h2><table><thead><tr><th style=text-align:left>函数</th><th style=text-align:left>#_flag</th><th style=text-align:left>#_bool</th><th style=text-align:left>指针类型</th><th style=text-align:left>整形类型</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left>test_and_set</td><td style=text-align:left>Y</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>将flag设为true并返回原先的值</td></tr><tr><td style=text-align:left>clear</td><td style=text-align:left>Y</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>将flag设为false</td></tr><tr><td style=text-align:left>is_lock_free</td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>检查原子变量是否免锁</td></tr><tr><td style=text-align:left>load</td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>返回原子变量的值</td></tr><tr><td style=text-align:left>store</td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>通过一个非原子变量的值设置原子变量的值</td></tr><tr><td style=text-align:left>exchange</td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>用新的值替换，并返回原先的值</td></tr><tr><td style=text-align:left>compare_exchange_weak compare_exchange_strong</td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>比较和改变值</td></tr><tr><td style=text-align:left>fetch_add, +=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>增加值</td></tr><tr><td style=text-align:left>fetch_sub, -=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>减少值</td></tr><tr><td style=text-align:left>++, &ndash;</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>Y</td><td style=text-align:left>自增和自减</td></tr><tr><td style=text-align:left>fetch_or, |=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>求或并赋值</td></tr><tr><td style=text-align:left>fetch_and, &=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>求与并赋值</td></tr><tr><td style=text-align:left>fetch_xor, ^=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left>求异或并赋值</td></tr></tbody></table><h3 id=memory_order>memory_order</h3><p>原子操作中,都支持一个类型为 <code>std::memory_order</code> 的可选参数。这个参数是一个枚举类型，可能的取值如下：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>typedef enum memory_order {
</span></span><span style=display:flex><span>    memory_order_relaxed,
</span></span><span style=display:flex><span>    memory_order_consume,
</span></span><span style=display:flex><span>    memory_order_acquire,
</span></span><span style=display:flex><span>    memory_order_release,
</span></span><span style=display:flex><span>    memory_order_acq_rel,
</span></span><span style=display:flex><span>    memory_order_seq_cst
</span></span><span style=display:flex><span>} memory_order;
</span></span></code></pre></div><p>首先，并非每一种<code>memory_order</code>对于每一个原子操作都有意义。它们的使用需要有特定的配合。</p><p>我们可以根据原子操作是否读写数据分为“Read”，“Write”以及“Read-Modify-Write”（读、修改、写）三类，下面是这些操作的分类。</p><table><thead><tr><th style=text-align:left>Operation</th><th style=text-align:left>Read</th><th style=text-align:left>Write</th><th style=text-align:left>Read-Modify-Write</th></tr></thead><tbody><tr><td style=text-align:left>test_and_set</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>clear</td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left></td></tr><tr><td style=text-align:left>is_lock_free</td><td style=text-align:left>Y</td><td style=text-align:left></td><td style=text-align:left></td></tr><tr><td style=text-align:left>load</td><td style=text-align:left>Y</td><td style=text-align:left></td><td style=text-align:left></td></tr><tr><td style=text-align:left>store</td><td style=text-align:left></td><td style=text-align:left>Y</td><td style=text-align:left></td></tr><tr><td style=text-align:left>exchange</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>compare_exchange_strong</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>compare_exchange_weak</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>fetch_add, +=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>fetch_sub, -=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>fetch_or, |=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>++,–</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>fetch_and, &=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr><tr><td style=text-align:left>fetch_xor, ^=</td><td style=text-align:left></td><td style=text-align:left></td><td style=text-align:left>Y</td></tr></tbody></table><p>而对于每一个分类，有意义的<code>memory_order</code>参数如下。</p><table><thead><tr><th style=text-align:left>Operation</th><th style=text-align:left>Order</th></tr></thead><tbody><tr><td style=text-align:left>Read</td><td style=text-align:left>memory_order_relaxed memory_order_consume memory_order_acquire memory_order_seq_cst</td></tr><tr><td style=text-align:left>Write</td><td style=text-align:left>memory_order_relaxed memory_order_release memory_order_seq_cst</td></tr><tr><td style=text-align:left>Read-modify-write</td><td style=text-align:left>memory_order_relaxed memory_order_acq_rel memory_order_seq_cst</td></tr></tbody></table><p>当多个线程中包含了多个原子操作，这些原子操作因为其<code>memory_order</code>的选择不一样，将导致运行时不同的内存模型强度。从强至弱，有三种情况：</p><ul><li>Sequential Consistency：顺序一致性，简称 seq-cst。</li><li>Acquire and Release：获取和释放，简称 acq-rel。</li><li>Relaxed：松散模型。</li></ul><h3 id=seq-cst-模型>seq-cst 模型</h3><p>当使用原子操作而又不指定<code>memory_order</code>时将使用默认的内存顺序：<code>memory_order_seq_cst</code>，因此调用这些函数时指定或者不指定这个值效果是一样的。</p><p>这是最严格的内存模型，seq-cst 有两个保证：</p><ul><li>程序指令与源码顺序一致</li><li>所有线程的所有操作存在一个全局的顺序</li></ul><p>这意味着：所有关于原子操作的代码都不会被乱序，你可以列出线程交错的所有可能性，即便每次执行交错的结果会不一样。但对于任意一次来说，其执行的顺序必属于这些可能性中的一个。而且，对于某一个单次执行来说，所有线程看到的顺序是一致的。</p><p>在这种模型下，每个线程中所有操作的先后关系，其顺序对于所有线程都是可见的。因此它是所有线程的全局同步。</p><p>这种模型很容易理解，但缺点是它的性能较差。因为为了实现顺序一致需要添加很多手段来对抗编译器和CPU的优化</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>#include&lt;bits/stdc++.h&gt; 
</span></span><span style=display:flex><span>std::atomic&lt;bool&gt; x,y;
</span></span><span style=display:flex><span>std::atomic&lt;int&gt; z;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>void write_x_then_y()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    x.store(true); // ①
</span></span><span style=display:flex><span>    y.store(true); // ②
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>void read_y_then_x()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    while(!y.load()); // ③
</span></span><span style=display:flex><span>    if(x.load()) // ④
</span></span><span style=display:flex><span>        ++z; // ⑤
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>int main()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    x=false;
</span></span><span style=display:flex><span>    y=false;
</span></span><span style=display:flex><span>    z=0;
</span></span><span style=display:flex><span>    std::thread a(write_x_then_y);
</span></span><span style=display:flex><span>    std::thread b(read_y_then_x);
</span></span><span style=display:flex><span>    a.join();
</span></span><span style=display:flex><span>    b.join();
</span></span><span style=display:flex><span>    assert(z.load()!=0); // ⑥
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>发生在线程a中的时序也将同步到线程b中。对于y的store和load操作构成了synchronized-with关系。</p><p>1 happens-before 2 happens-before 3 happens-before 4</p><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/seq_cst.png alt=img></p><h3 id=acq-rel-模型>acq-rel 模型</h3><p>memory_order_release对应了写操作，memory_order_acquire对应了读操作，memory_order_acq_rel对应了既读又写。</p><p>同一个原子变量上的acquire和release操作将引入synchronizes-with关系。除此之外，将不再有全局的一致顺序。</p><ul><li>同一个对象上的原子操作不允许被乱序。</li><li>release操作禁止了所有在它之前的读写操作与在它之后的写操作乱序。</li><li>acquire操作禁止了所有在它之前的读操作与在它之后的读写操作乱序。</li></ul><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>#include&lt;bits/stdc++.h&gt; 
</span></span><span style=display:flex><span>std::atomic&lt;bool&gt; x,y;
</span></span><span style=display:flex><span>std::atomic&lt;int&gt; z;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>void write_x_then_y()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    x.store(true, std::memory_order_relaxed); // ①
</span></span><span style=display:flex><span>    y.store(true, std::memory_order_release); // ②
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>void read_y_then_x()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    while(!y.load(std::memory_order_acquire)); // ③
</span></span><span style=display:flex><span>    if(x.load(std::memory_order_relaxed))
</span></span><span style=display:flex><span>        ++z;  // ④
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>int main()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    x=false;
</span></span><span style=display:flex><span>    y=false;
</span></span><span style=display:flex><span>    z=0;
</span></span><span style=display:flex><span>    std::thread a(write_x_then_y);
</span></span><span style=display:flex><span>    std::thread b(read_y_then_x);
</span></span><span style=display:flex><span>    a.join();
</span></span><span style=display:flex><span>    b.join();
</span></span><span style=display:flex><span>    assert(z.load()!=0); // ⑤
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/rel-acq.png alt=img></p><h3 id=relaxed-模型>relaxed 模型</h3><p>在进行原子操作时，指定memory_order_relaxed时将使用relaxed模型。这是最弱的内存模型。</p><p>这个模型下唯一可以保证的是：<strong>对于特定原子变量存在全局一致的修改顺序，除此以外不再有其他保</strong>证。这意味着，即便是同样的代码，不同的线程可能会看到不同的执行顺序。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>#include&lt;bits/stdc++.h&gt; 
</span></span><span style=display:flex><span>std::atomic&lt;bool&gt; x,y;
</span></span><span style=display:flex><span>std::atomic&lt;int&gt; z;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>void write_x_then_y()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    x.store(true, std::memory_order_relaxed); // ①
</span></span><span style=display:flex><span>    y.store(true, std::memory_order_relaxed); // ②
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>void read_y_then_x()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    while(!y.load(std::memory_order_relaxed)); // ③
</span></span><span style=display:flex><span>    if(x.load(std::memory_order_relaxed)) // ④
</span></span><span style=display:flex><span>        ++z;  // ⑤
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>int main()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    x=false;
</span></span><span style=display:flex><span>    y=false;
</span></span><span style=display:flex><span>    z=0;
</span></span><span style=display:flex><span>    std::thread a(write_x_then_y);
</span></span><span style=display:flex><span>    std::thread b(read_y_then_x);
</span></span><span style=display:flex><span>    a.join();
</span></span><span style=display:flex><span>    b.join();
</span></span><span style=display:flex><span>    assert(z.load()!=0); // ⑥
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>这里的assert是可能会触发的。</p><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/relaxed.png alt=img></p><ul><li>尽管所有操作都是原子的，但是所有的事件不要求存在一个全局顺序</li><li>同一个线程内部有happens-before规则，但是线程之间可能会看到不同的顺序</li></ul><p>另外需要说明的是：这里问题的发生只是<strong>理论上的可能</strong>。如果你将上面这个代码片段编译和运行，估计你运行100次也碰不到问题的发生。但是，这并不表示问题不存在，<strong>它只是很难发生而已</strong>。而这也恰恰是并发系统难以开发的原因之一：很多问题在绝大部分时候都不会出现，当在极少数时候发生的时候，又很难被理解。</p><p>relaxed模型约束太小，因此常常需要结合Fence来一起使用</p><h3 id=fence>Fence</h3><p>Fence这个单词的中文翻译就是“栅栏”，它就像一个屏障一样，使得其前后的代码不能穿越。</p><p>Fence有三种情况：</p><ul><li>full fence：指定了memory_order_seq_cst或者memory_order_acq_rel。</li><li>acquire fence：指定了memory_order_acquire。</li><li>release fence：指定了memory_order_release。</li></ul><p>不同类型的Fence对于乱序的保护是不一样的。我们可以将读和写的交错分成下面四种情况：</p><ul><li>① Load-Load：读接着读</li><li>② Load-Store：先读后写</li><li>③ Store-Load：先写后读</li><li>④ Store-Store：写接着写</li></ul><p>full fence可以防止①②④三种情况下，但是不能防止第③种情况下。</p><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/full_fence.png alt=img></p><p>acquire fence阻止了所有在它之前的读操作与在它之后的读写操作乱序</p><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/acquire_fence.png alt=img></p><p>release fence阻止了所有在它之前的读写操作与在它之后的写操作乱序</p><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/release_fence.png alt=img></p><p>使用fence修改relaxed的代码</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>std::atomic&lt;bool&gt; x,y;
</span></span><span style=display:flex><span>std::atomic&lt;int&gt; z;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>void write_x_then_y()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    x.store(true, std::memory_order_relaxed); // ①
</span></span><span style=display:flex><span>    std::  (std::memory_order_release);
</span></span><span style=display:flex><span>    y.store(true, std::memory_order_relaxed); // ②
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>void read_y_then_x()
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    while(!y.load(std::memory_order_relaxed)); // ③
</span></span><span style=display:flex><span>    std::atomic_thread_fence(std::memory_order_acquire);
</span></span><span style=display:flex><span>    if(x.load(std::memory_order_relaxed))
</span></span><span style=display:flex><span>        ++z;  // ④
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h3 id=mutex和fence>mutex和Fence</h3><p>之前我们介绍了互斥体<code>mutex</code>：拿到<code>mutex</code>锁的线程将拥有唯一进入临界区的资格。</p><p>除了保证互斥之外，其实<code>mutex</code>的加锁和解锁之间也起到了“栅栏”的作用。因为在栅栏里面的代码是怎么都不会被优化乱序到栅栏之外（但不保证栅栏之外的内容进入到栅栏之中）。</p><p>如下图的三种情况，第一种可能会被优化成第二种。但是第二种情况不会被优化成第三种：</p><p><img src=https://paul-pub.oss-cn-beijing.aliyuncs.com/2019/2019-12-05-cpp-memory-model/mutex-fence.png alt=img></p></div><footer class=post-footer><div class=post-tags><a href=/tags/c rel=tag title=C>#C#</a>
<a href=/tags/cpp rel=tag title=CPP>#CPP#</a></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.png width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>C++并发</p><p><span>链接：</span>http://rayrain.xyz/post/cpp_concurrency/</p><p><span>作者：</span>rayrain</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick='var qr=document.getElementById("QR");qr.style.display==="none"?qr.style.display="block":qr.style.display="none"'>
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div><div id=alipay style=display:inline-block><img id=alipay_qr src=/img/ali-pay.png alt=Alipay><p>支付宝打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"></div><div class="post-nav-prev post-nav-item"><a href=http://rayrain.xyz/post/parallel/ rel=prev title=并行编程>并行编程
<i class="fa fa-chevron-right"></i></a></div></div><div id=ucomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>文章目录</li><li class=sidebar-nav-overview data-target=site-overview>站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/avatar.png alt=rayrain><p class=site-author-name itemprop=name>rayrain</p><p class="site-description motion-element" itemprop=description>a righteoux</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>14</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>13</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>
标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/c>C</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/cpp>Cpp</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/linux>Linux</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/kernel>Kernel</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/qemu>Qemu</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/riscv>Riscv</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/elf>Elf</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/interview>Interview</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/shell>Shell</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/vim>Vim</a></li></ul></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#多线程编程>多线程编程</a><ul><li><a href=#future>future</a></li><li><a href=#async>async</a></li><li><a href=#promise>promise</a></li><li><a href=#packaged_task>packaged_task</a></li></ul></li><li><a href=#c内存模型>C++内存模型</a><ul><li><a href=#memory-reorder>Memory Reorder</a></li><li><a href=#sequenced-before>sequenced-before</a></li><li><a href=#happens-before>happens-before</a></li><li><a href=#synchronizes-with>synchronizes-with</a></li></ul></li><li><a href=#原子>原子</a><ul><li><a href=#memory_order>memory_order</a></li><li><a href=#seq-cst-模型>seq-cst 模型</a></li><li><a href=#acq-rel-模型>acq-rel 模型</a></li><li><a href=#relaxed-模型>relaxed 模型</a></li><li><a href=#fence>Fence</a></li><li><a href=#mutex和fence>mutex和Fence</a></li></ul></li></ul></nav></div></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=copyright-author>rayrain's blog</span></div><div class=powered-info><span class=powered-by>Powered by - <a class=powered-link href=//gohugo.io target=_blank title=hugo>Hugo v0.97.3</a></span>
<span class=separator-line>/</span>
<span class=theme-info>Theme by - <a class=powered-link href=//github.com/elkan1788/hugo-theme-next target=_blank>NexT</a></span></div><div class=vistor-info></div><div class=license-info><span class=storage-info>Storage by
<a href=https://pages.github.com/ style=font-weight:700 target=_blank>Github Pages</a></span>
<span class=separator-line>/</span>
<span class=license-num><a href=https://pages.github.com/ target=_blank>Xodom</a></span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i>
<span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script>
<script type=text/javascript src=/js/search.js></script>
<script type=text/javascript src=/js/affix.js></script>
<script type=text/javascript src=/js/scrollspy.js></script>
<script type=text/javascript>function detectIE(){var e=window.navigator.userAgent,t=e.indexOf("MSIE "),n=e.indexOf("Trident/"),s=e.indexOf("Edge/");return t>0||n>0||s>0?-1:1}function getCntViewHeight(){var t=$("#content").height(),e=$(window).height(),n=t>e?t-e:$(document).height()-e;return n}function getScrollbarWidth(){var e=$("<div />").addClass("scrollbar-measure").prependTo("body"),t=e[0],n=t.offsetWidth-t.clientWidth;return e.remove(),n}function registerBackTop(){var t=50,e=$(".back-to-top");$(window).on("scroll",function(){e.toggleClass("back-to-top-on",window.pageYOffset>t);var s=$(window).scrollTop(),o=getCntViewHeight(),i=s/o,n=Math.round(i*100),a=n>100?100:n;$("#scrollpercent>span").html(a)}),e.on("click",function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var e=".post-toc",s=$(e),t=".active-current";s.on("activate.bs.scrollspy",function(){var t=$(e+" .active").last();n(),t.addClass("active-current")}).on("clear.bs.scrollspy",n),$("body").scrollspy({target:e});function n(){$(e+" "+t).removeClass(t.substring(1))}}function initAffix(){var e=$(".header-inner").height(),t=parseInt($(".main").css("padding-bottom"),10),n=e+10;$(".sidebar-inner").affix({offset:{top:n,bottom:t}}),$(document).on("affixed.bs.affix",function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){$(window).on("resize",function(){e&&clearTimeout(e),e=setTimeout(function(){var e=document.body.clientHeight-100;updateTOCHeight(e)},0)}),updateTOCHeight(document.body.clientHeight-100);var e,t=getScrollbarWidth();$(".post-toc").css("width","calc(100% + "+t+"px)")}function updateTOCHeight(e){e=e||"auto",$(".post-toc").css("max-height",e)}$(function(){var e,t,n,s,o=$(".header-inner").height()+10;$("#sidebar").css({'margin-top':o}).show(),t=parseInt($("#sidebar").css("margin-top")),n=parseInt($(".sidebar-inner").css("height")),e=t+n,s=$(".content-wrap").height(),s<e&&$(".content-wrap").css("min-height",e),$(".site-nav-toggle").on("click",function(){var e=$(".site-nav"),o=$(".toggle"),t="site-nav-on",i="toggle-close",n=e.hasClass(t),a=n?"slideUp":"slideDown",s=n?"removeClass":"addClass";e.stop()[a]("normal",function(){e[s](t),o[s](i)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$(".sidebar-nav-toc").click(function(){$(this).addClass("sidebar-nav-active"),$(this).next().removeClass("sidebar-nav-active"),$("."+$(this).next().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)}),$(".sidebar-nav-overview").click(function(){$(this).addClass("sidebar-nav-active"),$(this).prev().removeClass("sidebar-nav-active"),$("."+$(this).prev().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script>
<script type=text/javascript>$(function(){$(".post-body").viewer()})</script><script src=//cdn.jsdelivr.net/npm/leancloud-storage@4.6.1/dist/av-min.js></script>
<script type=text/javascript>function showTime(s){var t=new AV.Query(s),e=[],n=$(".leancloud_visitors");n.each(function(){e.push($(this).attr("id").trim())}),t.containedIn("url",e),t.find().then(r=>{var t,s,o,a,c,l,i=".leancloud-visitors-count";if(r.length==0){n.find(i).text(0);return}for(t=0;t<r.length;t++)a=r[t],o=a.get("url"),l=a.get("time"),s=document.getElementById(o),$(s).find(i).text(l);for(t=0;t<e.length;t++)o=e[t],s=document.getElementById(o),c=$(s).find(i),c.text()==''&&c.text(0)},e=>{console.log("Query vistors failed: "+e)})}function addCount(s){var t=$(".leancloud_visitors"),e=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),n=new AV.Query("Counter");n.equalTo("url",e),n.find().then(i=>{if(i.length>0){var t,n,a=i[0];a.increment("time",1),a.save(null,{query:new AV.Query("Counter").equalTo("url",e),fetchWhenSave:!0}).then(t=>{var n=$(document.getElementById(e));n.find(".leancloud-visitors-count").text(t.get("time"))},e=>{console.log("Update vistor failed: "+e)})}else n=new AV.ACL,n.setPublicReadAccess(!0),n.setPublicWriteAccess(!0),t=new s,t.set("title",o),t.set("url",e),t.set("time",1),t.setACL(n),t.save().then(s=>{var n=$(document.getElementById(e));n.find(".leancloud-visitors-count").text(t.get("time"))},e=>{console.log("Save new vistor failed: "+e)})})}$(function(){AV.init({appId:"",appKey:"",serverURL:""});const e=AV.Object.extend("Counter");$(".leancloud_visitors").length==1?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script><script type=text/javascript>(function(){var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.setAttribute("issue-term","pathname"),e.setAttribute("theme","github-light"),e.setAttribute("repo","Reisen1969/Reisen1969.github.io"),e.crossorigin="anonymous",e.src="https://utteranc.es/client.js",document.getElementById("ucomments").appendChild(e)})()</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script>(function(){var t,e=document.createElement("script"),n=window.location.protocol.split(":")[0];n==="https"?e.src="https://zz.bdstatic.com/linksubmit/push.js":e.src="http://push.zhanzhang.baidu.com/push.js",t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script></body></html>